# üöÄ Scaling Guide for Hash API System

## üìã Overview

This guide explains how to properly scale your Hash API system both vertically and horizontally, identifies potential bottlenecks, and provides practical scaling strategies.

## üîÑ Scaling Types Explained

### üî∫ Vertical Scaling (Scale Up)
**Definition**: Adding more power (CPU, RAM) to existing machines/containers.

**Examples in our system**:
- Increasing CPU/memory limits for app containers
- Upgrading database server resources
- Adding more CPU cores to load balancer

**Characteristics**:
- ‚úÖ Simpler to implement
- ‚úÖ No architectural changes needed
- ‚ùå Physical hardware limits
- ‚ùå Single point of failure
- ‚ùå More expensive at scale

### üîª Horizontal Scaling (Scale Out)
**Definition**: Adding more machines/containers to handle increased load.

**Examples in our system**:
- Adding more app instances
- Adding more worker processes
- Database sharding (advanced)

**Characteristics**:
- ‚úÖ Theoretically unlimited scaling
- ‚úÖ Better fault tolerance
- ‚úÖ Cost-effective at scale
- ‚ùå More complex architecture
- ‚ùå Potential consistency issues

## üèóÔ∏è Component Scaling Analysis

### 1. **API Application Instances**
```bash
# Current: 3 instances
# Scale horizontally by adding more instances
docker-compose -f docker-compose.production.yml up -d --scale app1=10
```

**Scaling Type**: ‚úÖ **Horizontal** (Recommended)
- **Why**: Stateless application, perfect for horizontal scaling
- **Limit**: Load balancer capacity and database connections
- **Monitoring**: Check CPU/memory usage per instance

### 2. **Workers**
```bash
# Current: 3 workers
# Scale horizontally by adding more workers
docker-compose -f docker-compose.production.yml up -d --scale worker1=20
```

**Scaling Type**: ‚úÖ **Horizontal** (Recommended)
- **Why**: Independent task processors
- **Limit**: Database connection pool, task queue throughput
- **Note**: This is **horizontal scaling**, not vertical!

### 3. **Load Balancer**
```yaml
# Vertical scaling example
deploy:
  resources:
    limits:
      cpus: '4.0'      # Increased from 1.0
      memory: 2G       # Increased from 512M
```

**Scaling Type**: üî∫ **Vertical** (Primarily)
- **Why**: Single point of entry, state management for rate limiting
- **Horizontal Option**: Multiple load balancers with service discovery
- **Monitoring**: Check request throughput and response times

### 4. **Database (PostgreSQL)**
```yaml
# Vertical scaling example
deploy:
  resources:
    limits:
      cpus: '8.0'      # Increased from 2.0
      memory: 16G      # Increased from 2G
```

**Scaling Type**: üî∫ **Vertical** (Primarily)
- **Why**: ACID compliance, connection management
- **Horizontal Options**:
  - Read replicas for read-heavy workloads
  - Sharding for write-heavy workloads
  - Database clustering (advanced)

### 5. **Cache (Redis)**
```yaml
# Vertical scaling
deploy:
  resources:
    limits:
      memory: 2G       # Increased from 512M
```

**Scaling Type**: üî∫ **Vertical** (Primarily)
- **Horizontal Options**: Redis Cluster, Redis Sentinel
- **Alternative**: Use multiple Redis instances with consistent hashing

## üéØ Scaling Strategies by Use Case

### üìà High Request Volume
**Problem**: Too many API requests
**Solution**:
1. Scale API instances horizontally
2. Scale load balancer vertically
3. Optimize database queries

```bash
# Scale API instances
docker-compose -f docker-compose.production.yml up -d --scale app1=15 --scale app2=15 --scale app3=15

# Monitor performance
docker-compose -f docker-compose.production.yml exec loadbalancer curl http://localhost:8000/lb/stats
```

### üîÑ High Processing Load
**Problem**: Tasks taking too long to process
**Solution**:
1. Scale workers horizontally
2. Optimize task processing logic
3. Add more CPU to worker containers

```bash
# Scale workers
docker-compose -f docker-compose.production.yml up -d --scale worker1=30 --scale worker2=30 --scale worker3=30

# Monitor queue length
docker-compose -f docker-compose.production.yml exec db psql -U hashuser -d hashdb -c "SELECT COUNT(*) FROM tasks WHERE status = 'queued';"
```

### üóÉÔ∏è Database Bottleneck
**Problem**: Database is overloaded
**Solution**:
1. Scale database vertically
2. Implement connection pooling
3. Add read replicas
4. Optimize queries with indexes

```yaml
# Vertical database scaling
db:
  deploy:
    resources:
      limits:
        cpus: '8.0'
        memory: 16G
  command: |
    postgres
    -c max_connections=500      # Increased from 200
    -c shared_buffers=4GB       # Increased from 256MB
    -c effective_cache_size=12GB # Increased from 1GB
```

## üö® Bottleneck Identification

### 1. **Load Balancer Bottlenecks**
**Symptoms**:
- High response times
- Rate limiting triggering frequently
- High CPU usage on load balancer

**Solutions**:
```bash
# Check load balancer stats
curl http://localhost:8000/lb/stats

# Scale load balancer vertically
# Edit docker-compose.production.yml and increase resources
```

### 2. **Database Bottlenecks**
**Symptoms**:
- Long query times
- Connection pool exhaustion
- High database CPU/memory usage

**Solutions**:
```bash
# Check database performance
docker-compose -f docker-compose.production.yml exec db psql -U hashuser -d hashdb -c "SELECT * FROM pg_stat_activity;"

# Check connection pool stats
curl http://localhost:8000/db/pool/stats
```

### 3. **Worker Bottlenecks**
**Symptoms**:
- Growing task queue
- Long task processing times
- Workers idle due to database connections

**Solutions**:
```bash
# Check task queue length
docker-compose -f docker-compose.production.yml exec db psql -U hashuser -d hashdb -c "SELECT status, COUNT(*) FROM tasks GROUP BY status;"

# Scale workers
docker-compose -f docker-compose.production.yml up -d --scale worker1=50
```

### 4. **Memory Bottlenecks**
**Symptoms**:
- Container restarts due to OOM
- Swap usage increasing
- Cache hit rate dropping

**Solutions**:
```bash
# Check memory usage
docker stats

# Scale cache vertically
# Edit docker-compose.production.yml redis service
```

## üìä Monitoring and Metrics

### Key Metrics to Monitor

1. **Request Metrics**:
   - Requests per second
   - Response time (p95, p99)
   - Error rate

2. **Resource Metrics**:
   - CPU usage per service
   - Memory usage per service
   - Database connections

3. **Queue Metrics**:
   - Task queue length
   - Task processing time
   - Worker utilization

### Monitoring Setup
```bash
# Start monitoring services
docker-compose -f docker-compose.production.yml up -d prometheus grafana

# Access dashboards
open http://localhost:3000  # Grafana
open http://localhost:9090  # Prometheus
```

## üîß Practical Scaling Commands

### Quick Scale Up Commands
```bash
# Scale for high load
docker-compose -f docker-compose.production.yml up -d \
  --scale app1=10 \
  --scale app2=10 \
  --scale app3=10 \
  --scale worker1=20 \
  --scale worker2=20 \
  --scale worker3=20

# Scale for processing-heavy workload
docker-compose -f docker-compose.production.yml up -d \
  --scale worker1=50 \
  --scale worker2=50 \
  --scale worker3=50

# Scale back down
docker-compose -f docker-compose.production.yml up -d \
  --scale app1=3 \
  --scale worker1=3
```

### Resource Monitoring
```bash
# Check resource usage
docker stats

# Check service health
docker-compose -f docker-compose.production.yml ps

# Check logs
docker-compose -f docker-compose.production.yml logs -f --tail=100
```

## üéØ Performance Optimization Tips

### 1. **Database Optimization**
```sql
-- Add indexes for better query performance
CREATE INDEX CONCURRENTLY idx_tasks_status_created ON tasks(status, created_at);
CREATE INDEX CONCURRENTLY idx_cache_key_expires ON cache_entries(cache_key, expires_at);

-- Analyze query performance
EXPLAIN ANALYZE SELECT * FROM tasks WHERE status = 'queued' ORDER BY created_at LIMIT 10;
```

### 2. **Application Optimization**
- Use connection pooling
- Implement proper caching strategies
- Optimize serialization/deserialization
- Use asynchronous processing where possible

### 3. **Load Balancer Optimization**
- Tune rate limiting parameters
- Use least connections for variable processing times
- Implement health check timeouts

## üìà Scaling Roadmap

### Phase 1: Basic Scaling (Current)
- ‚úÖ Horizontal API scaling
- ‚úÖ Horizontal worker scaling
- ‚úÖ Basic load balancing
- ‚úÖ Connection pooling

### Phase 2: Advanced Scaling
- üîÑ Database read replicas
- üîÑ Redis clustering
- üîÑ Multiple load balancers
- üîÑ Auto-scaling based on metrics

### Phase 3: Enterprise Scaling
- üìã Database sharding
- üìã Microservices architecture
- üìã Service mesh
- üìã Multi-region deployment

## üöÄ Quick Reference

### Is Adding More Workers Vertical or Horizontal Scaling?

**Answer**: ‚úÖ **Horizontal Scaling**

**Explanation**:
- You're adding more worker **processes/containers**
- Each worker is an independent unit
- This increases **parallelism**, not individual worker power
- It's the same as adding more servers to handle load

### Component Scaling Summary

| Component | Preferred Scaling | Reason |
|-----------|-------------------|---------|
| API Apps | Horizontal | Stateless, load distributable |
| Workers | Horizontal | Independent task processors |
| Load Balancer | Vertical | Single point of entry |
| Database | Vertical | ACID compliance, consistency |
| Cache | Vertical | Memory-bound, simple architecture |

### Maximum Overload Points

1. **Load Balancer**: Request throughput, memory for rate limiting
2. **Database**: Connection limit, CPU for query processing
3. **Network**: Bandwidth between containers
4. **Host Resources**: Overall CPU, memory, disk I/O

The system is designed to handle failures gracefully, but these are the primary bottlenecks to monitor and scale appropriately.